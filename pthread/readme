
see below for the job queue model discussion.




The idea here is to dispatch a set of POSIX threads ( pthread ) which
receive some simple information from the calling main process and then
they just sleep based on what they were told to do. Then each pthread
will return some random data back to the main routine. Everything does
a bit of output and looking at the output pretty much reveals that we
have asynchronous stuff happening and then an neatly organized "join"
of those threads too.

The thread code is trivial : 

void *sleeper(void *recv_parm)
{
    thread_parm_t *p = (thread_parm_t *)recv_parm;

    printf("TRD  : %d sleeping %d seconds\n", p->tnum, p->sleep_time);
    sleep(p->sleep_time);
    printf("TRD  : %d awake\n", p->tnum);

    /* return some random data */
    p->ret_val = drand48();

    return (NULL);
}

Note that memory pressure is a very real thing and we can manage
some of that on Linux with : 

titan$ cat /proc/meminfo | grep -i 'commit'
CommitLimit:     6077292 kB
Committed_AS:      81192 kB
titan$ sysctl vm.overcommit_memory
vm.overcommit_memory = 0
titan$ sysctl vm.overcommit_ratio
vm.overcommit_ratio = 50
titan$ sysctl vm.overcommit_kbytes
vm.overcommit_kbytes = 0
titan$ wc -l /etc/sysctl.conf
68 /etc/sysctl.conf
titan$ sysctl -p  ^C
titan$ 
titan$ sysctl -w vm.overcommit_memory=1  ^C
titan$ 

see https://www.kernel.org/doc/html/v5.4/vm/overcommit-accounting.html


titan# 
titan# sysctl vm.overcommit_memory
vm.overcommit_memory = 0
titan# sysctl -w vm.overcommit_memory=1 
vm.overcommit_memory = 1
titan# sysctl vm.overcommit_memory
vm.overcommit_memory = 1
titan# cat /proc/meminfo | grep -i 'commit'
CommitLimit:     6077292 kB
Committed_AS:      79572 kB
titan# 

-------------- what about a job queue for these threads ? --------------

Consider the possibility of a collection of tasks or jobs that go into a
bucket. We need some way to drop the job information into the bucket and
some way to get access to the job information and also to clear the job
information out of the bucket. In the beginning we have an empty bucket
and we should end with an empty bucket once all tasks are complete.

We shall call this job bucket a "queue".

    +-------------+      +-------------+      +-------------+
    | job n       | ---> | job n+1     | ---> | job n+2     | --->X
    +-------------+      +-------------+      +-------------+

The above is a list of jobs in which we have some start point at job n
which could be n=0 or n=56. We could have the "first" job in the queue
as some number larger than zero if once upon a time there existed some
previous jobs that had already been handled. Regardless what we have for
the first value "n" in this list is ordered in that one task somehow
points to the next task in the overall queue list members. I would like
to point out that the list is ordered but the values of "n" need not be
ordered. This may be confusing but what I mean to say is that the number
n could point to some other task that has a number lessor or greater.

If we pick tasks out of the list and handles them in some way then we may
eventually end up with just the last task.  That last task will point to
nowhere at all as there are no more tasks.  It gets even better in that
we can even have a queue of nothing where there are no tasks at all.

The over all job list is inside a bucket we call a "queue" and the
beginning of this is the queue itself. Which begins empty. Then we have
the elements or task things inside the queue. These have to be separate
little things. Those separate little things should link to each other in
some sort of order.  I say "should" and not really a "must" but being
organized does make things more easy to deal with.

Lets consider a data structure thing that shall be our queue and we can
call it "q_type" which means a "queue data type" thing. It shall have a
few pointers inside it to queue items we shall call q_item types : 


    typedef struct q_type {

       /* We need a thing here which is 
        * the top or "head" of the list. */

        struct q_item *head;

       /* The end of the whole list will 
        * also exist as the "tail". */

        struct q_item *tail;

       /* It is nice to have a counter somewhere
        * to tell us how many things are in the queue */

        int length;

       /* We need a way to control access to
        * this list from many places and protect
        * us from multiple accesses happening at
        * the same time. Essentially protect us
        * from data corruption or inconsistent
        * queue elements. */

        pthread_mutex_t q_mutex;

        /* Is this queue live or dead?
         *
         * Here I am thinking that someday and someway
         * we need to have consumers or workers out there
         * that check if there is stuff in the queue as
         * well as a way to signal that we are shutting
         * down the whole queue.
         */
        pthread_cond_t alive;

    } q_type;


The above thing is actually the queue or bucket list. However we need a
thing to put in the queue. A task. A job.  A thing that somehow contains
the data we need that describes an element in the queue to be an actual
task to do : 


    typedef struct q_item {

        /* we need a way to stuff a data payload or 
         * parameter information load in this thing */

        void *payload;

        /* is there a next item in the list ? */

        struct q_item *next;

    } q_item;


We need some way for the queue thing to exist in memory somewhere. Since
everything in the C programming language boils down to accessing and 
manipulating stuff in memory somehow then we need a way for the queue to
exist in memory. Any variable we use will either be in some automatic
memory location which is also in a thing called a "memory stack" or it
may be a memory location that we have to ask for in a place called a big
"memory heap".  Just know that we have to have the queue in memory to do
anything with it.


I think it is best to have a way to setup the queue in memory as well as
a way to tear it down and remove it from memory.  For now we just want
to setup the queue thing in memory somewhere : 


    magic_function_thing () {

        make a request for a queue thing in memory somewhere please 

        inside the queue be sure the "head" and "tail" exist

        make sure "head" points nowhere as we do not have anything in the queue

        make sure "tail" also points nowhere for the same reason

        be sure the magic mutex thing exists and is setup somehow

        then return the shiney new queue to whomever called this magic function

    }


This new function will have to return a q_type data thing and thus the
function will have a datatype return value :

    q_type *q_create() {

        /* make a request for a queue thing in memory and
         * for extra special fun we want that memory to be
         * "clear".  That means all zeros in it. For this we
         * need one number element of a "struct q_type" thing. */

        struct q_type *q = calloc( (size_t) 1, (size_t) sizeof(struct q_type));

        /* make sure "head" and "tail" exist and 
         * since the queue is empty we want them both to 
         * be NULL pointers that point to nowhere. 
         *
         * Special note : we already asked above that the
         * memory be all set to zero and so this really is
         * not needed.  We do it anyways for clarity reasons.
         */
         q->head = NULL;
         q->tail = NULL;

        /* we know that the length of this queue is zero and
         * again we alread yasked for clean memory that is all
         * zeros but lets do this for clarity. */
        q->length = 0;

        /* be sure the magic mutex thing exists and is setup
         * as an initialized POSIX thread mutual exclusion lock
         * based on the macro PTHREAD_MUTEX_INITIALIZER */
        q->q_mutex = (pthread_mutex_t)PTHREAD_MUTEX_INITIALIZER;

        /* setup the alive condition as a POSIX thread "condition"
         * type thing. */
        q->alive = (pthread_cond_t)PTHREAD_COND_INITIALIZER;

        /* return the shiney new empty queue */
        return q;

    }


We now have a way to create a queue thing in memory and we even get back
a totally clear queue thing. What is the very first thing we will want
to do with a new shiney queue?  How about stuff something inside it?

At this time we should think about what type of a queue are we dealing
with?  For the sake of being real simple I am thinking of a FIFO queue
where stuff gets put into it and also taken out of in order. We do not
just randomly toss stuff into the queue nor do we randomly take stuff
out. Whatever goes in first is always going to be the "head" of a list
of things and then new stuff may be stuffed in after. The First stuff
in is also the First stuff Out.  This is FIFO queue type order.

We need a magic function again that somehow stuffs a thing into the 
queue : 

    magic_stuff_it_in_queue ( gimme a queue,
                              gimme task information to stuff in ) {

        first we need to protect the queue from other processes or
           other code wrangling with it

        we have been given some sort of task payload information and
          it now needs to get stuffed into the queue. We will need
          to create a new queue item thing and load it with the new
          task information "payload".

        is the queue list empty?  If it is then this is a new task to
           be put into a new queue where the head and tail of the queue
           are currently pointing nowhere.  Be sure to protect the 
           queue with the mutex lock thing.

        otherwise this is a new task to be added into the existing
           queue list. We may need to protect the queue from data
           corruption by locking it shut for just this stuff_it
           operation.

        we can now remove the protection from the queue as we have
           finished wrangling the contents inside it
   
        return back the number of items in the queue

    }


Lets try to write that magic in the C programming language now where
we say that we are putting something onto the end of the queue :

    int enqueue ( q_type *q, void *p ) {

        /* set the mutex as locked */
        pthread_mutex_lock ( &( q->q_mutex ) );

        /* we need to create a new queue item and put
         * the payload into it */
        struct q_item *new_item = calloc((size_t) 1, (size_t)sizeof(struct q_item));
        new_item->payload = p;

        /* we used calloc to give us clear memory but to be 
         * more obvious this item points to nowhere at the moment */
        new_item->next = NULL;

        /* Is the queue list empty? Check if head and tail
         * point nowhere OR even check if length is zero.
         *
         * To be clear the queue itself is NOT a linked 
         * list but rather the items inside it are linked.
         *
         * If the queue is empty then the head points to
         * nowhere as well as the tail. The length will
         * also be zero.  If there is only a single item
         * in the queue then the head and tail both point
         * to that single item. */

        if ( ( (q->length) == 0 )
            && ( (q->head) == NULL )
            && ( (q->tail) == NULL ) ) {

            /* the queue is indeed empty.
             *
             * Just place the new_item on the head and
             * the tail also is the same item and then
             * set the length to one.
             */
            q->head = new_item;
            q->tail = new_item;
            q->length = 1;

        } else {

            /* The queue is not empty.
             *
             * Take this new_item and stick it on the queue
             * tail. However we already have something on
             * the tail and we need to preserve that pointer.
             * Therefore whatever is on the tail now must
             * point to the new_item. Also the queue tail
             * will point to this new_item as it really is
             * now on the end of the list. 
             *
             *   +--------- queue -----------+
             *   |                           |
             *   |   head -->  some_item_N   |
             *   |                           |
             *   |   tail -->  some_item_X   |
             *   |                           |
             *   |   length =   3            |
             *   |                           |
             *   +---------------------------+
             *
             *   However the some_item_N looks like : 
             *
             *   +----- some_item_N ---------+
             *   |                           |
             *   |    payload = a_pointer_x  |
             *   |                           |
             *   |    next ---> some_item_P  |
             *   |                           | 
             *   +---------------------------+
             *
             *   +----- some_item_P ---------+
             *   |                           |
             *   |    payload = a_pointer_y  |
             *   |                           |
             *   |    next ---> some_item_X  |
             *   |                           | 
             *   +---------------------------+
             *
             *   +----- some_item_X ---------+
             *   |                           |
             *   |    payload = a_pointer_z  |
             *   |                           |
             *   |    next ---> NULL         |
             *   |                           |
             *   |      This "next" is also  |
             *   |      queue->tail->next    |
             *   |                           |
             *   +---------------------------+
             *
             */
            q->tail->next = new_item;
            q->tail = new_item;
            q->length += 1;

        }

        /* unlock the mutex */
        pthread_mutex_unlock ( &( q->q_mutex ) );

        /* send out a signal to at least one thread consumer
         * which may be waiting. No promise anything is actually
         * waiting but if there are then we signal that a new
         * task has arrived.
         *
         * From the manpage : 
         *
         *    The pthread_cond_signal() call unblocks at least one
         *    of the threads that are blocked on the specified
         *    condition variable condition. This is if any threads
         *    are blocked on cond.
         *
         */
        pthread_cond_signal( &( q->alive ) );

    }


How do we get anything out of that job list queue? 

Good question. We have to talk about a "consumer" thingy idea that 
eats up the tasks in the job queue. A consumer does what you think. It
goes looking for something to "eat" and if it finds something for it
then it "eats" the task up and as far as the queue is concerned the
problem is out of its hands.  We can get to consumer eating stuff later
but for now ... lets be able to get something from the task list.

    some_magic_get_job_thing ( some queue ) {

        protect the queue from all other threads accessing it 

        whoa nellie! check if the queue is empty ?
            we want to pop a task out of the queue but there is 
            nothing for us. We need to check the queue condition
            as being alive or dead.  This is where we await a
            signal that tells us the queue is good to go.

        If we had to wait for a signal then we are now fine and good
          because we definately have a task that we can pop from the
          queue.

        get a task item thing from the queue and here we must get the
          task item at the front of the list. This is a FIFO which 
          means that the first thing that went into the queue is also
          the first thing we take out.

        remove the protection

        return the task payload thing to whomever called for a "dequeue".

    }


Great. Not lets translate that into some sort of valid C code where
the objective is to remove something from the head of the queue :


    void *dequeue( q_type *q ) {

        void *return_payload = NULL;

        /* We only care about the first item in the queue and
         * we want the payload from that first item. Looking
         * at this diagram we see queue->head->payload is what
         * we want. 
         *
         *   +--------- queue -----------+
         *   |                           |
         *   |   head -->  some_item_N   |
         *   |                           |
         *   |   tail -->  some_item_X   |
         *   |                           |
         *   |   length =   3            |
         *   |                           |
         *   +---------------------------+
         *
         *   However the some_item_N looks like :
         *
         *   +----- some_item_N ---------+
         *   |                           |
         *   |    payload = a_pointer_x  |
         *   |                           |
         *   |    next ---> some_item_P  |
         *   |                           |
         *   +---------------------------+
         *
         * Once we get queue->head->payload then the item that
         * was called "some_item_N" no longer needs to exist.
         * The queue head must now point to whatever some_item_N
         * was pointing to as "next". That could even be NULL.
         */

        /* protect the queue from all other threads accessing it */
        pthread_mutex_lock ( &( q->q_mutex ) );

        /* check if the queue is empty and wait until it is alive */
        while ( ( (q->length) == 0 )
                && ( (q->head) == NULL )
                && ( (q->tail) == NULL ) ) {
        
            /* queue is empty so we await for it to get a task */
            pthread_cond_wait( &( q->alive ), &( q->q_mutex ) );

        }

        /* we now know for certain that the queue has something
         * at the head.  So get the payload that is pointed to. */
        return_payload = q->head->payload;

        /* redirect the head of the queue to point to whatever
         * was the next item, HOWEVER we need to save the 
         * current pointer data to free() the memory later */
        q_item *tmp=q->head;
        q->head = tmp->next;
        q->length -= 1;

        /* did we just empty the queue of the only item? */
        if ( ( q->length == 0 ) && ( q->head == NULL ) ) {
            q->tail = NULL;
        }

        /* free up the memory that was being used by the item
         * we just took the payload from */
        free(tmp);
        tmp = NULL;

        /* unlock the mutex */
        pthread_mutex_unlock ( &( q->q_mutex ) );

        return ( return_payload );
         
    }

------------------------------------------------------------------------
123456789+123456789+123456789+123456789+123456789+123456789+123456789+12

len$   
len$ valgrind -s --leak-check=full --leak-check=full --show-leak-kinds=all ./q_work 4
==2993== Memcheck, a memory error detector
==2993== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
==2993== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info
==2993== Command: ./q_work 4
==2993== 
-------------------------------------------------------------
           system name = Linux
             node name = lenovo
               release = 5.5.10-genunix
               version = #1 SMP Wed Mar 18 21:54:50 GMT 2020
               machine = x86_64
             page size = 4096
          avail memory = 5819428864
                       = 5683036 kB
                       = 5549 MB
                endian = little endian
 sizeof(unsigned long) = 8
           sizeof(int) = 4
         sizeof(void*) = 8
     fp rounding mode is FE_TONEAREST
-------------------------------------------------------------
INFO : num_pthreads is 4
INFO : about to call q_create()
DBUG : my_q now exists at 0x4b87500

INFO : q_push(make_work) done
     : my_q->length = 1

INFO : q_push(make_work) done
     : my_q->length = 2

INFO : q_push(make_work) done
     : my_q->length = 3

INFO : q_push(make_work) done
     : my_q->length = 4

     : about to call q_destroy(my_q)
     : q_destroy(my_q) says 0 items were thrown away
==2993== 
==2993== HEAP SUMMARY:
==2993==     in use at exit: 33,555,584 bytes in 12 blocks
==2993==   total heap usage: 19 allocs, 7 frees, 33,556,840 bytes allocated
==2993== 
==2993== 64 bytes in 4 blocks are still reachable in loss record 1 of 3
==2993==    at 0x4838B65: calloc (vg_replace_malloc.c:762)
==2993==    by 0x109917: main (q_work.c:108)
==2993== 
==2993== 1,088 bytes in 4 blocks are possibly lost in loss record 2 of 3
==2993==    at 0x4838B65: calloc (vg_replace_malloc.c:762)
==2993==    by 0x4011661: allocate_dtv (dl-tls.c:286)
==2993==    by 0x4011FAD: _dl_allocate_tls (dl-tls.c:532)
==2993==    by 0x4865C0E: allocate_stack (allocatestack.c:622)
==2993==    by 0x4865C0E: pthread_create@@GLIBC_2.2.5 (pthread_create.c:662)
==2993==    by 0x109AC4: main (q_work.c:144)
==2993== 
==2993== 33,554,432 bytes in 4 blocks are still reachable in loss record 3 of 3
==2993==    at 0x4838B65: calloc (vg_replace_malloc.c:762)
==2993==    by 0x109C22: do_some_array_thing (q_work.c:195)
==2993==    by 0x4864F26: start_thread (pthread_create.c:479)
==2993==    by 0x4ABF2EE: clone (clone.S:95)
==2993== 
==2993== LEAK SUMMARY:
==2993==    definitely lost: 0 bytes in 0 blocks
==2993==    indirectly lost: 0 bytes in 0 blocks
==2993==      possibly lost: 1,088 bytes in 4 blocks
==2993==    still reachable: 33,554,496 bytes in 8 blocks
==2993==         suppressed: 0 bytes in 0 blocks
==2993== 
==2993== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0)


